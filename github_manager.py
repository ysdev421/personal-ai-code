"""
GitHub çµ±åˆãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«
Chromadb ãƒ‡ãƒ¼ã‚¿ã‚’ GitHub ã«è‡ªå‹•ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—
"""

import os
import json
import subprocess
from datetime import datetime
from typing import Optional
import logging

logger = logging.getLogger(__name__)

class GitHubManager:
    """GitHub é€£æºãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼"""
    
    def __init__(self, repo_path: str = "."):
        """
        åˆæœŸåŒ–
        
        Args:
            repo_path: GitHub ãƒªãƒã‚¸ãƒˆãƒªã®ãƒ‘ã‚¹
        """
        self.repo_path = repo_path
        self.data_dir = os.path.join(repo_path, "data")
        
        # data/ ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒãªã‘ã‚Œã°ä½œæˆ
        if not os.path.exists(self.data_dir):
            os.makedirs(self.data_dir)
            logger.info(f"ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ: {self.data_dir}")
    
    def export_chromadb_to_json(self, collection) -> dict:
        """
        Chromadb ã®ãƒ‡ãƒ¼ã‚¿ã‚’ JSON å½¢å¼ã§ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ
        
        Args:
            collection: Chromadb ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³
        
        Returns:
            dict: ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿
        """
        try:
            all_data = collection.get()
            
            export_data = {
                'timestamp': datetime.now().isoformat(),
                'total_documents': len(all_data['documents']),
                'documents': all_data['documents'],
                'metadatas': all_data['metadatas'],
                'ids': all_data['ids']
            }
            
            logger.info(f"Chromadb ã‚’ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ: {len(all_data['documents'])} ä»¶")
            return export_data
        
        except Exception as e:
            logger.error(f"ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆã‚¨ãƒ©ãƒ¼: {e}")
            return {}
    
    def save_backup(self, data: dict, filename: str = "backup.json") -> bool:
        """
        ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
        
        Args:
            data: ä¿å­˜ã™ã‚‹ãƒ‡ãƒ¼ã‚¿
            filename: ãƒ•ã‚¡ã‚¤ãƒ«å
        
        Returns:
            bool: æˆåŠŸã—ãŸã‹
        """
        try:
            filepath = os.path.join(self.data_dir, filename)
            
            with open(filepath, 'w', encoding='utf-8') as f:
                json.dump(data, f, indent=2, ensure_ascii=False)
            
            logger.info(f"ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ä¿å­˜: {filepath}")
            return True
        
        except Exception as e:
            logger.error(f"ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}")
            return False
    
    def commit_and_push(self, message: Optional[str] = None) -> bool:
        """
        Git ã‚³ãƒŸãƒƒãƒˆï¼†ãƒ—ãƒƒã‚·ãƒ¥
        
        Args:
            message: ã‚³ãƒŸãƒƒãƒˆãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
        
        Returns:
            bool: æˆåŠŸã—ãŸã‹
        """
        try:
            if message is None:
                message = f"Auto backup: {datetime.now().isoformat()}"
            
            # ãƒªãƒã‚¸ãƒˆãƒªã®ãƒã‚§ãƒƒã‚¯
            if not os.path.exists(os.path.join(self.repo_path, ".git")):
                logger.warning("Git ãƒªãƒã‚¸ãƒˆãƒªãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚ã‚¹ã‚­ãƒƒãƒ—")
                return False
            
            # git add
            result = subprocess.run(
                ['git', 'add', 'data/'],
                cwd=self.repo_path,
                capture_output=True,
                text=True
            )
            
            if result.returncode != 0:
                logger.error(f"git add ã‚¨ãƒ©ãƒ¼: {result.stderr}")
                return False
            
            logger.info("git add å®Œäº†")
            
            # git commit
            result = subprocess.run(
                ['git', 'commit', '-m', message],
                cwd=self.repo_path,
                capture_output=True,
                text=True
            )
            
            if result.returncode != 0:
                logger.warning(f"git commit: {result.stderr}")
                # ã‚³ãƒŸãƒƒãƒˆã™ã‚‹ã‚‚ã®ãŒãªã„å ´åˆã‚‚ã‚ã‚Š
            
            logger.info("git commit å®Œäº†")
            
            # git push
            result = subprocess.run(
                ['git', 'push', 'origin', 'main'],
                cwd=self.repo_path,
                capture_output=True,
                text=True,
                timeout=30
            )
            
            if result.returncode != 0:
                logger.error(f"git push ã‚¨ãƒ©ãƒ¼: {result.stderr}")
                return False
            
            logger.info("git push å®Œäº†")
            return True
        
        except subprocess.TimeoutExpired:
            logger.error("git push ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ")
            return False
        except Exception as e:
            logger.error(f"Git æ“ä½œã‚¨ãƒ©ãƒ¼: {e}")
            return False
    
    def auto_backup(self, collection, commit: bool = True) -> bool:
        """
        è‡ªå‹•ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ï¼ˆã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆï¼†ä¿å­˜ï¼†ãƒ—ãƒƒã‚·ãƒ¥ï¼‰
        
        Args:
            collection: Chromadb ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³
            commit: Git ãƒ—ãƒƒã‚·ãƒ¥ã™ã‚‹ã‹
        
        Returns:
            bool: æˆåŠŸã—ãŸã‹
        """
        logger.info("=== è‡ªå‹•ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—é–‹å§‹ ===")
        
        # Step 1: ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ
        data = self.export_chromadb_to_json(collection)
        if not data:
            return False
        
        # Step 2: ä¿å­˜
        if not self.save_backup(data):
            return False
        
        # Step 3: Git ãƒ—ãƒƒã‚·ãƒ¥
        if commit:
            if not self.commit_and_push(
                message=f"Auto backup: {len(data['documents'])} documents"
            ):
                logger.warning("Git ãƒ—ãƒƒã‚·ãƒ¥ã«å¤±æ•—ã—ã¾ã—ãŸãŒã€ãƒ­ãƒ¼ã‚«ãƒ«ä¿å­˜ã¯æˆåŠŸ")
                return False
        
        logger.info("=== è‡ªå‹•ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—å®Œäº† ===")
        return True
    
    def load_backup(self, filename: str = "backup.json") -> Optional[dict]:
        """
        ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã‚€
        
        Args:
            filename: ãƒ•ã‚¡ã‚¤ãƒ«å
        
        Returns:
            dict or None: èª­ã¿è¾¼ã‚“ã ãƒ‡ãƒ¼ã‚¿
        """
        try:
            filepath = os.path.join(self.data_dir, filename)
            
            if not os.path.exists(filepath):
                logger.warning(f"ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {filepath}")
                return None
            
            with open(filepath, 'r', encoding='utf-8') as f:
                data = json.load(f)
            
            logger.info(f"ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—èª­ã¿è¾¼ã¿: {filepath}")
            return data
        
        except Exception as e:
            logger.error(f"ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
            return None
    
    def export_purchases(self, collection) -> None:
        """
        è³¼å…¥ãƒ‡ãƒ¼ã‚¿ã‚’åˆ¥ãƒ•ã‚¡ã‚¤ãƒ«ã«ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ
        
        Args:
            collection: Chromadb ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³
        """
        try:
            # è³¼å…¥ãƒ‡ãƒ¼ã‚¿ã‚’æ¤œç´¢
            results = collection.get(
                where={"type": "purchase"}
            )
            
            purchases = {
                'timestamp': datetime.now().isoformat(),
                'total': len(results['documents']),
                'purchases': [
                    {
                        'id': results['ids'][i],
                        'content': results['documents'][i],
                        'metadata': results['metadatas'][i]
                    }
                    for i in range(len(results['documents']))
                ]
            }
            
            filepath = os.path.join(self.data_dir, "purchases.json")
            with open(filepath, 'w', encoding='utf-8') as f:
                json.dump(purchases, f, indent=2, ensure_ascii=False)
            
            logger.info(f"è³¼å…¥ãƒ‡ãƒ¼ã‚¿: {filepath} ã«ä¿å­˜")
        
        except Exception as e:
            logger.error(f"è³¼å…¥ãƒ‡ãƒ¼ã‚¿ ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆã‚¨ãƒ©ãƒ¼: {e}")
    
    def export_conversations(self, collection) -> None:
        """
        ä¼šè©±ãƒ‡ãƒ¼ã‚¿ã‚’åˆ¥ãƒ•ã‚¡ã‚¤ãƒ«ã«ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ
        
        Args:
            collection: Chromadb ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³
        """
        try:
            # ä¼šè©±ãƒ‡ãƒ¼ã‚¿ã‚’æ¤œç´¢
            results = collection.get(
                where={"type": "conversation"}
            )
            
            conversations = {
                'timestamp': datetime.now().isoformat(),
                'total': len(results['documents']),
                'conversations': [
                    {
                        'id': results['ids'][i],
                        'content': results['documents'][i],
                        'metadata': results['metadatas'][i]
                    }
                    for i in range(len(results['documents']))
                ]
            }
            
            filepath = os.path.join(self.data_dir, "conversations.json")
            with open(filepath, 'w', encoding='utf-8') as f:
                json.dump(conversations, f, indent=2, ensure_ascii=False)
            
            logger.info(f"ä¼šè©±ãƒ‡ãƒ¼ã‚¿: {filepath} ã«ä¿å­˜")
        
        except Exception as e:
            logger.error(f"ä¼šè©±ãƒ‡ãƒ¼ã‚¿ ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆã‚¨ãƒ©ãƒ¼: {e}")
    
    def create_weekly_summary(self, week_number: int) -> None:
        """
        é€±é–“ã‚µãƒãƒªãƒ¼ã‚’ä½œæˆ
        
        Args:
            week_number: é€±ç•ªå·
        """
        try:
            filename = f"weekly/week_{week_number:02d}.md"
            filepath = os.path.join(self.data_dir, filename)
            
            # ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ
            os.makedirs(os.path.dirname(filepath), exist_ok=True)
            
            # ã‚µãƒãƒªãƒ¼å†…å®¹
            content = f"""# Week {week_number:02d} Summary

## ğŸ“Š Statistics
- Generated: {datetime.now().isoformat()}

## ğŸ’¬ Conversations
- Total: (è‡ªå‹•è¨ˆç®—)

## ğŸ’³ Purchases
- Total: (è‡ªå‹•è¨ˆç®—)

## ğŸ“ Notes
- 

## ğŸ“ˆ Next Week Goals
-
"""
            
            with open(filepath, 'w', encoding='utf-8') as f:
                f.write(content)
            
            logger.info(f"é€±é–“ã‚µãƒãƒªãƒ¼ä½œæˆ: {filepath}")
        
        except Exception as e:
            logger.error(f"é€±é–“ã‚µãƒãƒªãƒ¼ä½œæˆã‚¨ãƒ©ãƒ¼: {e}")


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# backend_server.py ã«çµ„ã¿è¾¼ã‚€ç”¨
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

"""
backend_server.py ã«ä»¥ä¸‹ã‚’è¿½åŠ ï¼š

from github_manager import GitHubManager

# ã‚°ãƒ­ãƒ¼ãƒãƒ«
github_manager = GitHubManager(".")  # ãƒªãƒã‚¸ãƒˆãƒªã®ãƒ‘ã‚¹

# ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©ãƒ¼ã«è¿½åŠ 
async def daily_backup():
    '''æ¯æ—¥æ·±å¤œ 0:00 ã«ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—'''
    github_manager.auto_backup(collection, commit=True)

scheduler.add_job(
    daily_backup,
    'cron',
    hour=0,
    minute=0,
    name='daily_backup'
)

# ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ ã‚¿ã‚¹ã‚¯
async def export_data():
    '''æ¯é€±æ—¥æ›œ 21:00 ã«è©³ç´°ãƒ‡ãƒ¼ã‚¿ã‚’ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ'''
    github_manager.export_purchases(collection)
    github_manager.export_conversations(collection)
    
    # é€±é–“ã‚µãƒãƒªãƒ¼ä½œæˆ
    from datetime import date
    week_num = date.today().isocalendar()[1]
    github_manager.create_weekly_summary(week_num)

scheduler.add_job(
    export_data,
    'cron',
    day_of_week='sun',
    hour=21,
    minute=0,
    name='weekly_export'
)
"""
