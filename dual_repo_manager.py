"""
GitHub ãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼ï¼ˆ2 ãƒªãƒã‚¸ãƒˆãƒªå¯¾å¿œï¼‰
- personal-ai-code: ã‚½ãƒ¼ã‚¹ã‚³ãƒ¼ãƒ‰ï¼ˆPublicï¼‰
- personal-ai-data: å€‹äººãƒ‡ãƒ¼ã‚¿ï¼ˆPrivateï¼‰
"""

import os
import json
import subprocess
from datetime import datetime
from typing import Optional
import logging

logger = logging.getLogger(__name__)

class DualRepositoryManager:
    """2 ã¤ã®ãƒªãƒã‚¸ãƒˆãƒªã‚’ç®¡ç†"""
    
    def __init__(self, 
                 code_repo_path: str = "../personal-ai-code",
                 data_repo_path: str = "../personal-ai-data"):
        """
        åˆæœŸåŒ–
        
        Args:
            code_repo_path: ã‚½ãƒ¼ã‚¹ã‚³ãƒ¼ãƒ‰ãƒªãƒã‚¸ãƒˆãƒªã®ãƒ‘ã‚¹
            data_repo_path: ãƒ‡ãƒ¼ã‚¿ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ãƒªãƒã‚¸ãƒˆãƒªã®ãƒ‘ã‚¹
        """
        self.code_repo_path = code_repo_path
        self.data_repo_path = data_repo_path
        self.data_dir = os.path.join(data_repo_path, "data")
        
        # data/ ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒãªã‘ã‚Œã°ä½œæˆ
        if not os.path.exists(self.data_dir):
            os.makedirs(self.data_dir)
            logger.info(f"ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ: {self.data_dir}")
    
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # ã€ãƒªãƒã‚¸ãƒˆãƒª 1ã€‘ã‚½ãƒ¼ã‚¹ã‚³ãƒ¼ãƒ‰ç®¡ç†
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    
    def push_source_code(self, message: Optional[str] = None) -> bool:
        """
        ã‚½ãƒ¼ã‚¹ã‚³ãƒ¼ãƒ‰ã‚’ GitHub ã« pushï¼ˆå¿…è¦ã«å¿œã˜ã¦ï¼‰
        
        Args:
            message: ã‚³ãƒŸãƒƒãƒˆãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
        
        Returns:
            bool: æˆåŠŸã—ãŸã‹
        """
        try:
            if message is None:
                message = f"Update: {datetime.now().isoformat()}"
            
            # ãƒªãƒã‚¸ãƒˆãƒªã®ãƒã‚§ãƒƒã‚¯
            if not os.path.exists(os.path.join(self.code_repo_path, ".git")):
                logger.warning("ã‚½ãƒ¼ã‚¹ã‚³ãƒ¼ãƒ‰ãƒªãƒã‚¸ãƒˆãƒªãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
                return False
            
            # git add
            subprocess.run(
                ['git', 'add', '.'],
                cwd=self.code_repo_path,
                capture_output=True
            )
            
            # git commit
            result = subprocess.run(
                ['git', 'commit', '-m', message],
                cwd=self.code_repo_path,
                capture_output=True,
                text=True
            )
            
            # git push
            result = subprocess.run(
                ['git', 'push', 'origin', 'main'],
                cwd=self.code_repo_path,
                capture_output=True,
                text=True,
                timeout=30
            )
            
            if result.returncode == 0:
                logger.info(f"ã‚½ãƒ¼ã‚¹ã‚³ãƒ¼ãƒ‰ push: {message}")
                return True
            else:
                logger.warning(f"ã‚½ãƒ¼ã‚¹ã‚³ãƒ¼ãƒ‰ push å¤±æ•—: {result.stderr}")
                return False
        
        except Exception as e:
            logger.error(f"ã‚½ãƒ¼ã‚¹ã‚³ãƒ¼ãƒ‰ push ã‚¨ãƒ©ãƒ¼: {e}")
            return False
    
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # ã€ãƒªãƒã‚¸ãƒˆãƒª 2ã€‘å€‹äººãƒ‡ãƒ¼ã‚¿ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    
    def export_chromadb_to_json(self, collection) -> dict:
        """
        Chromadb ã®ãƒ‡ãƒ¼ã‚¿ã‚’ JSON å½¢å¼ã§ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ
        
        Args:
            collection: Chromadb ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³
        
        Returns:
            dict: ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿
        """
        try:
            all_data = collection.get()
            
            export_data = {
                'timestamp': datetime.now().isoformat(),
                'total_documents': len(all_data['documents']),
                'documents': all_data['documents'],
                'metadatas': all_data['metadatas'],
                'ids': all_data['ids']
            }
            
            logger.info(f"Chromadb ã‚’ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ: {len(all_data['documents'])} ä»¶")
            return export_data
        
        except Exception as e:
            logger.error(f"ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆã‚¨ãƒ©ãƒ¼: {e}")
            return {}
    
    def save_backup_data(self, data: dict, filename: str = "backup.json") -> bool:
        """
        ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
        
        Args:
            data: ä¿å­˜ã™ã‚‹ãƒ‡ãƒ¼ã‚¿
            filename: ãƒ•ã‚¡ã‚¤ãƒ«å
        
        Returns:
            bool: æˆåŠŸã—ãŸã‹
        """
        try:
            filepath = os.path.join(self.data_dir, filename)
            
            with open(filepath, 'w', encoding='utf-8') as f:
                json.dump(data, f, indent=2, ensure_ascii=False)
            
            logger.info(f"ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ä¿å­˜: {filepath}")
            return True
        
        except Exception as e:
            logger.error(f"ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}")
            return False
    
    def push_backup_data(self, message: Optional[str] = None) -> bool:
        """
        å€‹äººãƒ‡ãƒ¼ã‚¿ã‚’ GitHub ã« push
        
        Args:
            message: ã‚³ãƒŸãƒƒãƒˆãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
        
        Returns:
            bool: æˆåŠŸã—ãŸã‹
        """
        try:
            if message is None:
                message = f"Auto backup: {datetime.now().isoformat()}"
            
            # ãƒªãƒã‚¸ãƒˆãƒªã®ãƒã‚§ãƒƒã‚¯
            if not os.path.exists(os.path.join(self.data_repo_path, ".git")):
                logger.warning("ãƒ‡ãƒ¼ã‚¿ãƒªãƒã‚¸ãƒˆãƒªãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
                return False
            
            # git add data/ ã®ã¿
            subprocess.run(
                ['git', 'add', 'data/'],
                cwd=self.data_repo_path,
                capture_output=True
            )
            
            # git commit
            result = subprocess.run(
                ['git', 'commit', '-m', message],
                cwd=self.data_repo_path,
                capture_output=True,
                text=True
            )
            
            # git push
            result = subprocess.run(
                ['git', 'push', 'origin', 'main'],
                cwd=self.data_repo_path,
                capture_output=True,
                text=True,
                timeout=30
            )
            
            if result.returncode == 0:
                logger.info(f"ãƒ‡ãƒ¼ã‚¿ push: {message}")
                return True
            else:
                logger.warning(f"ãƒ‡ãƒ¼ã‚¿ push å¤±æ•—ï¼ˆç„¡è¦–ï¼‰: {result.stderr}")
                # ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚¨ãƒ©ãƒ¼ãªã©ã§ã‚‚ç¶šè¡Œ
                return False
        
        except subprocess.TimeoutExpired:
            logger.warning("ãƒ‡ãƒ¼ã‚¿ push ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆï¼ˆç„¡è¦–ï¼‰")
            return False
        except Exception as e:
            logger.error(f"ãƒ‡ãƒ¼ã‚¿ push ã‚¨ãƒ©ãƒ¼ï¼ˆç„¡è¦–ï¼‰: {e}")
            return False
    
    async def auto_backup(self, collection) -> bool:
        """
        è‡ªå‹•ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ï¼ˆã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆï¼†ä¿å­˜ï¼†ãƒ—ãƒƒã‚·ãƒ¥ï¼‰
        
        Args:
            collection: Chromadb ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³
        
        Returns:
            bool: æˆåŠŸã—ãŸã‹
        """
        logger.info("=== è‡ªå‹•ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—é–‹å§‹ ===")
        
        # Step 1: ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ
        data = self.export_chromadb_to_json(collection)
        if not data:
            return False
        
        # Step 2: ä¿å­˜
        if not self.save_backup_data(data):
            return False
        
        # Step 3: GitHub ã« push
        self.push_backup_data(
            message=f"Auto backup: {len(data['documents'])} documents"
        )
        
        logger.info("=== è‡ªå‹•ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—å®Œäº† ===")
        return True
    
    def export_purchases(self, collection) -> None:
        """è³¼å…¥ãƒ‡ãƒ¼ã‚¿ã‚’åˆ¥ãƒ•ã‚¡ã‚¤ãƒ«ã«ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ"""
        try:
            results = collection.get(
                where={"type": "purchase"}
            )
            
            purchases = {
                'timestamp': datetime.now().isoformat(),
                'total': len(results['documents']),
                'purchases': [
                    {
                        'id': results['ids'][i],
                        'content': results['documents'][i],
                        'metadata': results['metadatas'][i]
                    }
                    for i in range(len(results['documents']))
                ]
            }
            
            filepath = os.path.join(self.data_dir, "purchases.json")
            with open(filepath, 'w', encoding='utf-8') as f:
                json.dump(purchases, f, indent=2, ensure_ascii=False)
            
            logger.info(f"è³¼å…¥ãƒ‡ãƒ¼ã‚¿: {filepath} ã«ä¿å­˜")
        
        except Exception as e:
            logger.error(f"è³¼å…¥ãƒ‡ãƒ¼ã‚¿ ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆã‚¨ãƒ©ãƒ¼: {e}")
    
    def export_conversations(self, collection) -> None:
        """ä¼šè©±ãƒ‡ãƒ¼ã‚¿ã‚’åˆ¥ãƒ•ã‚¡ã‚¤ãƒ«ã«ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ"""
        try:
            results = collection.get(
                where={"type": "conversation"}
            )
            
            conversations = {
                'timestamp': datetime.now().isoformat(),
                'total': len(results['documents']),
                'conversations': [
                    {
                        'id': results['ids'][i],
                        'content': results['documents'][i],
                        'metadata': results['metadatas'][i]
                    }
                    for i in range(len(results['documents']))
                ]
            }
            
            filepath = os.path.join(self.data_dir, "conversations.json")
            with open(filepath, 'w', encoding='utf-8') as f:
                json.dump(conversations, f, indent=2, ensure_ascii=False)
            
            logger.info(f"ä¼šè©±ãƒ‡ãƒ¼ã‚¿: {filepath} ã«ä¿å­˜")
        
        except Exception as e:
            logger.error(f"ä¼šè©±ãƒ‡ãƒ¼ã‚¿ ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆã‚¨ãƒ©ãƒ¼: {e}")
    
    def create_weekly_summary(self, week_number: int) -> None:
        """é€±é–“ã‚µãƒãƒªãƒ¼ã‚’ä½œæˆ"""
        try:
            weekly_dir = os.path.join(self.data_dir, "weekly")
            os.makedirs(weekly_dir, exist_ok=True)
            
            filename = f"week_{week_number:02d}.md"
            filepath = os.path.join(weekly_dir, filename)
            
            content = f"""# Week {week_number:02d} Summary

Generated: {datetime.now().isoformat()}

## ğŸ“Š Statistics

## ğŸ’¬ Conversations

## ğŸ’³ Purchases

## ğŸ“ Notes

## ğŸ“ˆ Next Week Goals
"""
            
            with open(filepath, 'w', encoding='utf-8') as f:
                f.write(content)
            
            logger.info(f"é€±é–“ã‚µãƒãƒªãƒ¼ä½œæˆ: {filepath}")
        
        except Exception as e:
            logger.error(f"é€±é–“ã‚µãƒãƒªãƒ¼ä½œæˆã‚¨ãƒ©ãƒ¼: {e}")
    
    def push_all(self, collection) -> None:
        """
        å…¨ã¦ã‚’ pushï¼ˆæ‰‹å‹•ã§å‘¼ã¶ç”¨ï¼‰
        
        Args:
            collection: Chromadb ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³
        """
        logger.info("å…¨ãƒªãƒã‚¸ãƒˆãƒªã« push é–‹å§‹...")
        
        # ãƒ‡ãƒ¼ã‚¿ã‚’ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆï¼†ä¿å­˜
        self.export_purchases(collection)
        self.export_conversations(collection)
        
        # é€±é–“ã‚µãƒãƒªãƒ¼
        from datetime import date
        week_num = date.today().isocalendar()[1]
        self.create_weekly_summary(week_num)
        
        # ãƒ‡ãƒ¼ã‚¿ãƒªãƒã‚¸ãƒˆãƒªã« push
        self.push_backup_data(f"Weekly update: {datetime.now()}")
        
        logger.info("å…¨ push å®Œäº†")
